<html>
  <head> </head>

  <body>
    <!-- <script src="https://cdn.jsdelivr.net/npm/onnxjs/dist/onnx.min.js"></script> -->
    <!-- <script src="https://cdn.jsdelivr.net/npm/onnxjs@0.1.7/dist/onnx.min.js"></script> -->
    <script src="./onnx.min.js"></script>
    <script src="http://danml.com/js/download.js"></script>


    <h1>Extract CLIP RN50 embedding</h1>

    <div>
      This is just for demo, the preprocessing step on image is not applied, images are just [0, 1] normalized before fed to the model.
      Thus ebds differ from the real ebds with the whole pre-processing.
      <br/>
      Warning: only give as input already 224x224 cropped images. (as I told you I didn't implemented the preprocessing step).
      <br/>
    </div>
    
    <div>
      <input id="imgUrl" type="text" placeholder="image url" value="./image224.jpg"/>
      <button onclick="load_model()">Load model</button>
      <button onclick="extract_ebds()">Comute and Download embeddings</button>

      <div id="info"></div>
    </div>
    

    <canvas id="canvas"></canvas>
    
    <script>
        async function loadImage(url) {
            return new Promise((resolve, reject) => {
                const img = new Image();
                img.crossOrigin = "anonymous";
                img.onload = () => resolve(img);
                img.onerror = reject;
                img.src = url;
            });
        }

        async function imageToTensor(url) {
            const img = await loadImage(url);
            const canvas = document.getElementById('canvas');
            const ctx = canvas.getContext('2d');
            canvas.width = img.width;
            canvas.height = img.height;
            ctx.drawImage(img, 0, 0, img.width, img.height);

            const imageData = ctx.getImageData(0, 0, img.width, img.height);
            const data = imageData.data;
            const floatData = new Float32Array(data.length / 4 * 3);
       
            dataLn = data.length
            for (c= 0; c < 3; c ++) {
              for (i = 0; i < dataLn / 4; i++) {
                floatData[c * dataLn / 4 + i] = data[i * 4 + c] / 255;
              }
            }
            
            const tensor = new onnx.Tensor(floatData, 'float32', [1, 3, img.height, img.width]);
            return tensor;
        }

        
    </script>
    <script>
      // create a session
      const myOnnxSession = new onnx.InferenceSession({
        backendHint: 'webgl'
      });


      async function load_model() {
          document.getElementById("info").innerText = "loading model";
          await myOnnxSession.loadModel("./clip_rn50.onnx");
          document.getElementById("info").innerText = "model loaded!";
      }

      async function extract_ebds() {
        document.getElementById("info").innerText = "loading model";
        url = document.getElementById("imgUrl").value;
        myImageTensor = await imageToTensor(url);
        document.getElementById("info").innerText = "image loaded…\nextracting embedding…";
        o = await myOnnxSession.run([myImageTensor]);
        ebd = o.values().next().value;
        console.log(ebd)
        document.getElementById("info").innerText = "embedding computed (you can check the console)\ndownloading embedding…"
        download(JSON.stringify(ebd.data), "ebd.json", "text/json")
      }

    </script>
  </body>
</html>

